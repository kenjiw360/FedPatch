{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b82d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import socket\n",
    "import threading\n",
    "import struct\n",
    "import io\n",
    "\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "\tdef __init__(self, model, port=65432, buffer_cap=9):\n",
    "\t\t# Model Initialisation\n",
    "\t\tself.model = model\n",
    "\n",
    "\t\t# Networking Initialisation\n",
    "\t\tself.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\t\tself.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n",
    "\t\tself.socket.bind(('', port))\n",
    "\n",
    "\t\t# Buffer Initialisation\n",
    "\t\tself.buffer_cap = buffer_cap\n",
    "\t\tself.buffer = []\n",
    "\n",
    "\t\t# Patches Initialisation\n",
    "\t\tself.patches = {}\n",
    "\n",
    "\t\tself.round = 0\n",
    "\t\n",
    "\tdef buffer_client(self, client, address, data):\n",
    "\t\tprint(f\"Adding {address} To Buffer...\")\n",
    "\n",
    "\t\tdecoded = data.decode().replace(\"Training Complete, \", \"\").split(\", \")\n",
    "\n",
    "\t\tsize = int(decoded[0])\n",
    "\n",
    "\t\tserver_info = tuple([decoded[1],int(decoded[2])])\n",
    "\n",
    "\t\tprint(size, server_info)\n",
    "\n",
    "\t\tself.buffer.append((client, address, size, server_info)) # Add Client Into Buffer\n",
    "\t\tprint(f\"Buffer Population: {len(self.buffer)}/{self.buffer_cap}\")\n",
    "\t\tif len(self.buffer) == self.buffer_cap:\n",
    "\t\t\tprint(\"Beginning Decentralised Aggregation...\")\n",
    "\t\t\t# Kick Off Decentralised Aggregation\n",
    "\t\t\tfor i in range(len(self.buffer)): self.buffer[i][0].sendall(f\"Decentralised Aggregation: {', '.join([f'{N}#{address[0]}:{address[1]}#{server_address[0]}:{server_address[1]}' for (client, address, N, server_address) in self.buffer])}\".encode())\n",
    "\n",
    "\t\t\tself.patches = [[address, None] for (client, address, N, server_address) in self.buffer]\n",
    "\n",
    "\t\t\tself.round += 1\n",
    "\t\t\tself.buffer = []\n",
    "\n",
    "\tdef stitch(self, client, id):\n",
    "\t\tdata_size = b''\n",
    "\t\twhile len(data_size) < 4:\n",
    "\t\t\tdata_size += client.recv(4 - len(data_size))\n",
    "\t\tdata_size = struct.unpack(\">I\", data_size)[0]\n",
    "\n",
    "\t\tresult = b\"\"\n",
    "\n",
    "\t\twhile len(result) < data_size:\n",
    "\t\t\tdata = client.recv(1024)\n",
    "\t\t\tresult += data\n",
    "\t\t\n",
    "\t\tself.patches[id][1] = pickle.loads(result)\n",
    "\n",
    "\t\tfor patch_info in self.patches:\n",
    "\t\t\tif patch_info[1] == None: return\n",
    "\n",
    "\t\tprint(\"Received All Patches, Beginning Stitching Process...\")\n",
    "\t\t\n",
    "\t\tstate_dict = OrderedDict()\n",
    "\t\tfor name, param in self.model.state_dict().items():\n",
    "\t\t\tstate_dict[name] = torch.reshape(torch.cat([patch[name] for [addr, patch] in self.patches]).flatten(), param.shape)\n",
    "\t\t\n",
    "\t\tprint(\"Finished Stitching Together All Patches!\")\n",
    "\n",
    "\t\tprint(\"Loading Patched `state_dict` Into Model... \", end=\"\")\n",
    "\t\tself.model.load_state_dict(state_dict)\n",
    "\t\tprint(\"Done!\")\n",
    "\n",
    "\t\ttorch.save(state_dict, 'model.pt')\n",
    "\n",
    "\t\tprint(\"Saving Patched `state_dict` To Disk... \", end=\"\")\n",
    "\t\tprint(\"Done!\")\n",
    "\n",
    "\tdef listen_helper(self, client, address):\n",
    "\t\tprint(f\"Connected To {address}...\")\n",
    "\t\t\n",
    "\t\tbuffer = io.BytesIO()\n",
    "\t\ttorch.save(self.model.state_dict(), buffer)\n",
    "\t\tbuffer.seek(0)\n",
    "\n",
    "\t\tfor i, [patch_address, patch] in enumerate(self.patches):\n",
    "\t\t\tif address == patch_address and patch is None:\n",
    "\t\t\t\treturn self.stitch(client, i)\n",
    "\n",
    "\t\tclient.sendall(struct.pack('>I', buffer.getbuffer().nbytes)) # Send Size Of Buffer\n",
    "\t\tclient.sendall(buffer.read()) # Send Model State In Bytes\n",
    "\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdata = client.recv(64)\n",
    "\t\t\t\tif not data: break\n",
    "\n",
    "\t\t\t\t# User Finished Training\n",
    "\t\t\t\tif data == b\"Round Number\": client.sendall(struct.pack('>I', self.round))\n",
    "\t\t\t\tif b\"Training Complete, \" in data: self.buffer_client(client, address, data)\n",
    "\t\t\texcept ConnectionResetError:\n",
    "\t\t\t\tbreak\n",
    "\t\tclient.close()\n",
    "\t\tprint(f\"Connection To {address} Closed...\")\n",
    "\n",
    "\tdef listen(self):\n",
    "\t\tself.socket.listen()\n",
    "\t\tprint(f\"Listening On Port {self.socket.getsockname()[1]}\")\n",
    "\t\twhile True:\n",
    "\t\t\tclient, address = self.socket.accept()\n",
    "\t\t\tthread = threading.Thread(target=self.listen_helper, args=(client, address))\n",
    "\t\t\tthread.start()\n",
    "\n",
    "\tdef evaluate(self):\n",
    "\t\tself.model.eval()\n",
    "\t\tprint(\"Should Evaluate Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267c500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18()\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "model.to(torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52044d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server(model, buffer_cap=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd5263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening On Port 65432\n",
      "Connected To ('127.0.0.1', 58593)...\n",
      "Connected To ('127.0.0.1', 58598)...\n",
      "Connection To ('127.0.0.1', 58598) Closed...\n",
      "Connected To ('127.0.0.1', 58622)...\n",
      "Connection To ('127.0.0.1', 58622) Closed...\n",
      "Adding ('127.0.0.1', 58593) To Buffer...\n",
      "5555 ('0.0.0.0', 58592)\n",
      "Buffer Population: 1/2\n",
      "Connected To ('127.0.0.1', 58637)...\n",
      "Connection To ('127.0.0.1', 58637) Closed...\n",
      "Connected To ('127.0.0.1', 58648)...\n",
      "Connected To ('127.0.0.1', 58662)...\n",
      "Connection To ('127.0.0.1', 58662) Closed...\n",
      "Connection To ('127.0.0.1', 58648) Closed...\n",
      "Connected To ('127.0.0.1', 58665)...\n",
      "Connected To ('127.0.0.1', 58667)...\n",
      "Connection To ('127.0.0.1', 58667) Closed...\n",
      "Connection To ('127.0.0.1', 58665) Closed...\n",
      "Connected To ('127.0.0.1', 58748)...\n",
      "Connection To ('127.0.0.1', 58748) Closed...\n",
      "Connected To ('127.0.0.1', 58752)...\n",
      "Adding ('127.0.0.1', 58752) To Buffer...\n",
      "5555 ('0.0.0.0', 58751)\n",
      "Buffer Population: 2/2\n",
      "Beginning Decentralised Aggregation...\n",
      "Patch Data:  [[('127.0.0.1', 58593), None], [('127.0.0.1', 58752), None]]\n",
      "Connection To ('127.0.0.1', 58752) Closed...\n",
      "Connection To ('127.0.0.1', 58593) Closed...\n",
      "Connected To ('127.0.0.1', 58593)...\n",
      "Connected To ('127.0.0.1', 58752)...\n",
      "Received All Patches, Beginning Stitching Process...\n",
      "Working on Layer conv1.weight\n",
      "Working on Layer bn1.weight\n",
      "Working on Layer bn1.bias\n",
      "Working on Layer bn1.running_mean\n",
      "Working on Layer bn1.running_var\n",
      "Working on Layer bn1.num_batches_tracked\n",
      "Working on Layer layer1.0.conv1.weight\n",
      "Working on Layer layer1.0.bn1.weight\n",
      "Working on Layer layer1.0.bn1.bias\n",
      "Working on Layer layer1.0.bn1.running_mean\n",
      "Working on Layer layer1.0.bn1.running_var\n",
      "Working on Layer layer1.0.bn1.num_batches_tracked\n",
      "Working on Layer layer1.0.conv2.weight\n",
      "Working on Layer layer1.0.bn2.weight\n",
      "Working on Layer layer1.0.bn2.bias\n",
      "Working on Layer layer1.0.bn2.running_mean\n",
      "Working on Layer layer1.0.bn2.running_var\n",
      "Working on Layer layer1.0.bn2.num_batches_tracked\n",
      "Working on Layer layer1.1.conv1.weight\n",
      "Working on Layer layer1.1.bn1.weight\n",
      "Working on Layer layer1.1.bn1.bias\n",
      "Working on Layer layer1.1.bn1.running_mean\n",
      "Working on Layer layer1.1.bn1.running_var\n",
      "Working on Layer layer1.1.bn1.num_batches_tracked\n",
      "Working on Layer layer1.1.conv2.weight\n",
      "Working on Layer layer1.1.bn2.weight\n",
      "Working on Layer layer1.1.bn2.bias\n",
      "Working on Layer layer1.1.bn2.running_mean\n",
      "Working on Layer layer1.1.bn2.running_var\n",
      "Working on Layer layer1.1.bn2.num_batches_tracked\n",
      "Working on Layer layer2.0.conv1.weight\n",
      "Working on Layer layer2.0.bn1.weight\n",
      "Working on Layer layer2.0.bn1.bias\n",
      "Working on Layer layer2.0.bn1.running_mean\n",
      "Working on Layer layer2.0.bn1.running_var\n",
      "Working on Layer layer2.0.bn1.num_batches_tracked\n",
      "Working on Layer layer2.0.conv2.weight\n",
      "Working on Layer layer2.0.bn2.weight\n",
      "Working on Layer layer2.0.bn2.bias\n",
      "Working on Layer layer2.0.bn2.running_mean\n",
      "Working on Layer layer2.0.bn2.running_var\n",
      "Working on Layer layer2.0.bn2.num_batches_tracked\n",
      "Working on Layer layer2.0.downsample.0.weight\n",
      "Working on Layer layer2.0.downsample.1.weight\n",
      "Working on Layer layer2.0.downsample.1.bias\n",
      "Working on Layer layer2.0.downsample.1.running_mean\n",
      "Working on Layer layer2.0.downsample.1.running_var\n",
      "Working on Layer layer2.0.downsample.1.num_batches_tracked\n",
      "Working on Layer layer2.1.conv1.weight\n",
      "Working on Layer layer2.1.bn1.weight\n",
      "Working on Layer layer2.1.bn1.bias\n",
      "Working on Layer layer2.1.bn1.running_mean\n",
      "Working on Layer layer2.1.bn1.running_var\n",
      "Working on Layer layer2.1.bn1.num_batches_tracked\n",
      "Working on Layer layer2.1.conv2.weight\n",
      "Working on Layer layer2.1.bn2.weight\n",
      "Working on Layer layer2.1.bn2.bias\n",
      "Working on Layer layer2.1.bn2.running_mean\n",
      "Working on Layer layer2.1.bn2.running_var\n",
      "Working on Layer layer2.1.bn2.num_batches_tracked\n",
      "Working on Layer layer3.0.conv1.weight\n",
      "Working on Layer layer3.0.bn1.weight\n",
      "Working on Layer layer3.0.bn1.bias\n",
      "Working on Layer layer3.0.bn1.running_mean\n",
      "Working on Layer layer3.0.bn1.running_var\n",
      "Working on Layer layer3.0.bn1.num_batches_tracked\n",
      "Working on Layer layer3.0.conv2.weight\n",
      "Working on Layer layer3.0.bn2.weight\n",
      "Working on Layer layer3.0.bn2.bias\n",
      "Working on Layer layer3.0.bn2.running_mean\n",
      "Working on Layer layer3.0.bn2.running_var\n",
      "Working on Layer layer3.0.bn2.num_batches_tracked\n",
      "Working on Layer layer3.0.downsample.0.weight\n",
      "Working on Layer layer3.0.downsample.1.weight\n",
      "Working on Layer layer3.0.downsample.1.bias\n",
      "Working on Layer layer3.0.downsample.1.running_mean\n",
      "Working on Layer layer3.0.downsample.1.running_var\n",
      "Working on Layer layer3.0.downsample.1.num_batches_tracked\n",
      "Working on Layer layer3.1.conv1.weight\n",
      "Working on Layer layer3.1.bn1.weight\n",
      "Working on Layer layer3.1.bn1.bias\n",
      "Working on Layer layer3.1.bn1.running_mean\n",
      "Working on Layer layer3.1.bn1.running_var\n",
      "Working on Layer layer3.1.bn1.num_batches_tracked\n",
      "Working on Layer layer3.1.conv2.weight\n",
      "Working on Layer layer3.1.bn2.weight\n",
      "Working on Layer layer3.1.bn2.bias\n",
      "Working on Layer layer3.1.bn2.running_mean\n",
      "Working on Layer layer3.1.bn2.running_var\n",
      "Working on Layer layer3.1.bn2.num_batches_tracked\n",
      "Working on Layer layer4.0.conv1.weight\n",
      "Working on Layer layer4.0.bn1.weight\n",
      "Working on Layer layer4.0.bn1.bias\n",
      "Working on Layer layer4.0.bn1.running_mean\n",
      "Working on Layer layer4.0.bn1.running_var\n",
      "Working on Layer layer4.0.bn1.num_batches_tracked\n",
      "Working on Layer layer4.0.conv2.weight\n",
      "Working on Layer layer4.0.bn2.weight\n",
      "Working on Layer layer4.0.bn2.bias\n",
      "Working on Layer layer4.0.bn2.running_mean\n",
      "Working on Layer layer4.0.bn2.running_var\n",
      "Working on Layer layer4.0.bn2.num_batches_tracked\n",
      "Working on Layer layer4.0.downsample.0.weight\n",
      "Working on Layer layer4.0.downsample.1.weight\n",
      "Working on Layer layer4.0.downsample.1.bias\n",
      "Working on Layer layer4.0.downsample.1.running_mean\n",
      "Working on Layer layer4.0.downsample.1.running_var\n",
      "Working on Layer layer4.0.downsample.1.num_batches_tracked\n",
      "Working on Layer layer4.1.conv1.weight\n",
      "Working on Layer layer4.1.bn1.weight\n",
      "Working on Layer layer4.1.bn1.bias\n",
      "Working on Layer layer4.1.bn1.running_mean\n",
      "Working on Layer layer4.1.bn1.running_var\n",
      "Working on Layer layer4.1.bn1.num_batches_tracked\n",
      "Working on Layer layer4.1.conv2.weight\n",
      "Working on Layer layer4.1.bn2.weight\n",
      "Working on Layer layer4.1.bn2.bias\n",
      "Working on Layer layer4.1.bn2.running_mean\n",
      "Working on Layer layer4.1.bn2.running_var\n",
      "Working on Layer layer4.1.bn2.num_batches_tracked\n",
      "Working on Layer fc.weight\n",
      "Working on Layer fc.bias\n",
      "Finished Stitching Together All Patches!\n",
      "Loading Patched `state_dict` Into Model... Done!\n",
      "Saving Patched `state_dict` To Disk... Done!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m server.listen()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mServer.listen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mListening On Port \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.socket.getsockname()[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \tclient, address = \u001b[38;5;28mself\u001b[39m.socket.accept()\n\u001b[32m    111\u001b[39m \tthread = threading.Thread(target=\u001b[38;5;28mself\u001b[39m.listen_helper, args=(client, address))\n\u001b[32m    112\u001b[39m \tthread.start()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research/lib/python3.12/socket.py:295\u001b[39m, in \u001b[36msocket.accept\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    289\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"accept() -> (socket object, address info)\u001b[39;00m\n\u001b[32m    290\u001b[39m \n\u001b[32m    291\u001b[39m \u001b[33;03m    Wait for an incoming connection.  Return a new socket\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    representing the connection, and the address of the client.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m    For IP sockets, the address info is a pair (hostaddr, port).\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     fd, addr = \u001b[38;5;28mself\u001b[39m._accept()\n\u001b[32m    296\u001b[39m     sock = socket(\u001b[38;5;28mself\u001b[39m.family, \u001b[38;5;28mself\u001b[39m.type, \u001b[38;5;28mself\u001b[39m.proto, fileno=fd)\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m# Issue #7995: if no default timeout is set and the listening\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# socket had a (non-zero) timeout, force the new socket in blocking\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# mode to override platform-specific socket flags inheritance.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "server.listen()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
